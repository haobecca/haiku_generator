{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "9OyPiHVvRRVs",
    "outputId": "a8ac6478-e547-43c3-e897-0d0c4b0741c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cmudict in /usr/local/lib/python3.6/dist-packages (0.4.3)\n"
     ]
    }
   ],
   "source": [
    "# Install cmudict, not included in colab env\n",
    "!pip install cmudict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oGx15VBOSSRx"
   },
   "outputs": [],
   "source": [
    "# Authenticate Google Drive Access\n",
    "# Comment out if not running this on colab\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ruh2BjKGSaG-"
   },
   "outputs": [],
   "source": [
    "count_syllables = drive.CreateFile({'id':'1CGKlsOz9C12RcatJT6iheJrW0Tq7dPvL'})\n",
    "count_syllables.GetContentFile('count_syllables.py')\n",
    "\n",
    "missing_words = drive.CreateFile({'id':'1IoXlh3r7-eXip3UPA4hEoHtscZJZ7som'})\n",
    "missing_words.GetContentFile('missing_words.json')\n",
    "\n",
    "train = drive.CreateFile({'id':'1L-xLounIWPWjJx78D_26HGubVvyGEDOO'})\n",
    "train.GetContentFile('train.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cumOiQpERRVv"
   },
   "outputs": [],
   "source": [
    "from count_syllables import count_syllables\n",
    "import random\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Widget for user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "6R36nHJHRRVy",
    "outputId": "2d2acd13-698d-4136-e8e7-685001b61cff",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e9bdac83844ee8a1b611ef2e28d241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='What would you like to generate?', options=('full haiku', 'line 2 only', 'line 3 only'),â€¦"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Colab does not render the widget\n",
    "# Default option is to generate the full haiku\n",
    "\n",
    "style = {'description_width': 'initial'}\n",
    "regen = widgets.Dropdown(options=['full haiku', 'line 2 only', 'line 3 only'],\n",
    "                 value = 'full haiku',\n",
    "                 description = 'What would you like to generate?',\n",
    "                 disabled = False,\n",
    "                 style=style)\n",
    "\n",
    "display(regen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training corpus and create Markov chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Qszz5CyRRV0"
   },
   "outputs": [],
   "source": [
    "# Load a training-corpus text file\n",
    "with open('train.txt', 'r') as f:\n",
    "    train = f.read()\n",
    "\n",
    "# Process the training corpus for spaces, newline breaks, and so on\n",
    "punc = '!,.?~:\\\"'\n",
    "#train = train.translate(str.maketrans('', '', punc))\n",
    "train_list = train.split()\n",
    "\n",
    "# Map each word in corpus to the word after (Markov model order 1)\n",
    "train_dict_o1 = dict()\n",
    "\n",
    "# Map each word pair in corpus to the word after (Markov model order 2)\n",
    "train_dict_o2 = dict()\n",
    "\n",
    "# Populate both corpus dictionaries simultaneously\n",
    "for first, second, third in zip(train_list, train_list[1:], train_list[2:]):\n",
    "    if first in train_dict_o1:\n",
    "        train_dict_o1[first].append(second)\n",
    "    else:\n",
    "        train_dict_o1[first] = [second]\n",
    "    if (first, second) in train_dict_o2:\n",
    "            train_dict_o2[first, second].append(third)\n",
    "    else:\n",
    "        train_dict_o2[first, second] = [third]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c6hCO6lJRRV5"
   },
   "outputs": [],
   "source": [
    "def rand_o1():\n",
    "    '''\n",
    "    randomly picks a word from the order 1 Markov chain keys\n",
    "    '''\n",
    "    word = random.choice(list(train_dict_o1.keys())) \n",
    "    return word\n",
    "\n",
    "def rand_o2():\n",
    "    '''\n",
    "    generate a word by randomly picking a key from the order 2 Markov chain\n",
    "    '''\n",
    "    seed_word = random.choice(list(train_dict_o2.keys()))\n",
    "    mapped_word = random.choice(train_dict_o2[seed_word])\n",
    "    return mapped_word\n",
    "\n",
    "def follow_word(sentence = ['we', 'saw'], target = 5, syl = 2):\n",
    "    '''\n",
    "    generate followings words using the order 2 markov chain\n",
    "    '''\n",
    "    while syl < target:\n",
    "        seed_word = tuple(sentence)\n",
    "        \n",
    "        try:\n",
    "            mapped_word = random.choice(train_dict_o2[seed_word])\n",
    "        except KeyError: \n",
    "            mapped_word = rand_o1()\n",
    "            \n",
    "        mapped_word_syl = count_syllables(mapped_word)\n",
    "        \n",
    "        if syl + mapped_word_syl <= target:\n",
    "            sentence.append(mapped_word)\n",
    "            syl += mapped_word_syl\n",
    "        else:\n",
    "            mapped_word = rand_o2()\n",
    "            mapped_word_syl = count_syllables(mapped_word)\n",
    "            \n",
    "            if syl + mapped_word_syl <= target:\n",
    "                sentence.append(mapped_word)  \n",
    "                syl += mapped_word_syl\n",
    "                \n",
    "    print(syl) \n",
    "    sentence = \" \".join(sentence)\n",
    "    return(sentence)\n",
    "\n",
    "def new_line1():\n",
    "    '''\n",
    "    generates first line of the haiku\n",
    "    '''\n",
    "    target = 5\n",
    "    syl= target + 1\n",
    "    \n",
    "    # Pick a random first word that's fewer than 5 syllables from the order 1 markov chain\n",
    "    while syl > target:\n",
    "        first_word = rand_o1()\n",
    "        \n",
    "        # Generate the second word using the order 1 markov chain\n",
    "        try:\n",
    "            second_word = random.choice(train_dict_o1[first_word])\n",
    "        except KeyError: \n",
    "            second_word = rand_o1()\n",
    "        \n",
    "        syl = count_syllables(first_word) + count_syllables(second_word)\n",
    "        \n",
    "    sentence1 = [first_word, second_word]\n",
    "    \n",
    "    # Generate followings words using the order 2 markov chain\n",
    "    sentence1 = follow_word(sentence1)\n",
    "    return sentence1\n",
    "\n",
    "def new_line23(prev_sen = 'deep autumn water hill', target = 5):\n",
    "    '''\n",
    "    generates second or third line of the haiku\n",
    "    '''\n",
    "    syl = target + 1\n",
    "    \n",
    "    # Take the last two words from the previous sentence as the seed words for the order 2 markov chain\n",
    "    seed_word = tuple(prev_sen.split()[-2::])\n",
    "    while syl > target:\n",
    "\n",
    "        try:\n",
    "            first_word = random.choice(train_dict_o2[seed_word])\n",
    "        except KeyError: \n",
    "            first_word = rand_o1()\n",
    "            \n",
    "        seed_word = tuple([prev_sen[-1], first_word])\n",
    "        \n",
    "        try:\n",
    "            second_word = random.choice(train_dict_o2[seed_word])\n",
    "        except KeyError: \n",
    "            second_word = rand_o1()\n",
    "            \n",
    "        syl = count_syllables(first_word) + count_syllables(second_word) \n",
    "        \n",
    "    sentence = [first_word, second_word] \n",
    "    \n",
    "    # Generate followings words using the order 2 markov chain\n",
    "    sentence = follow_word(sentence, target, syl)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's build the haiku!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "48mpo9SDRRV7",
    "outputId": "53d9fdd7-11e0-430b-ed37-6279b34b71d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "7\n",
      "5\n",
      "utter end wander end\n",
      "once hollow noons swordhand hill's\n",
      "fence dancing banks sticks\n"
     ]
    }
   ],
   "source": [
    "line = regen.value\n",
    "\n",
    "# Colab does not render the widget\n",
    "# Default option is to generate the full haiku\n",
    "# If you wish to generate line 2 or 3 only comment out the aline above and uncomment the following corresponding lines\n",
    "\n",
    "# line = 'line 2 only'\n",
    "# line = 'line 3 only'\n",
    "\n",
    "def haiku(line):\n",
    "    '''\n",
    "    generates the haiku based on user selection\n",
    "    '''\n",
    "    \n",
    "    # Define starter sentences\n",
    "\n",
    "    sentence1 = \"round lumps of cells grows\"\n",
    "    sentence2 = \"up to love porridge later\"\n",
    "    sentence3 = \"become The Supremes\"\n",
    "    \n",
    "    if line == 'full haiku':\n",
    "        sentence1 = new_line1()\n",
    "        sentence2 = new_line23(sentence1, 7)\n",
    "        sentence3 = new_line23(sentence2, 5)\n",
    "        \n",
    "    if line == 'line 2 only':\n",
    "        sentence2 = new_line23(sentence1, 7)\n",
    "        \n",
    "    if line == 'line 3 only':\n",
    "        sentence3 = new_line23(sentence2, 5)\n",
    "        \n",
    "    for x in [sentence1, sentence2, sentence3]:\n",
    "        print(x)\n",
    "\n",
    "haiku(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hwUWj8HiRRV9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of haiku.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
