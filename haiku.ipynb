{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from count_syllables import count_syllables\n",
    "import random\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e3da4accee43bda8c60d657f4e3749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='What would you like to generate?', options=('full haiku', 'line 2 only', 'line 3 only'),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "style = {'description_width': 'initial'}\n",
    "regen = widgets.Dropdown(options=['full haiku', 'line 2 only', 'line 3 only'],\n",
    "                 value = 'full haiku',\n",
    "                 description = 'What would you like to generate?',\n",
    "                 disabled = False,\n",
    "                 style=style)\n",
    "\n",
    "display(regen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a training-corpus text file\n",
    "with open('train.txt', 'r') as f:\n",
    "    train = f.read()\n",
    "\n",
    "# Process the training corpus for spaces, newline breaks, and so on\n",
    "punc = '!,.?~:\\\"'\n",
    "train = train.translate(str.maketrans('', '', punc))\n",
    "train_list = train.split()\n",
    "\n",
    "# Map each word in corpus to the word after (Markov model order 1)\n",
    "train_dict_o1 = dict()\n",
    "\n",
    "# Map each word pair in corpus to the word after (Markov model order 2)\n",
    "train_dict_o2 = dict()\n",
    "\n",
    "# Populate both corpus dictionaries simultaneously\n",
    "for first, second, third in zip(train_list, train_list[1:], train_list[2:]):\n",
    "    if first in train_dict_o1:\n",
    "        train_dict_o1[first].append(second)\n",
    "    else:\n",
    "        train_dict_o1[first] = [second]\n",
    "    if (first, second) in train_dict_o2:\n",
    "            train_dict_o2[first, second].append(third)\n",
    "    else:\n",
    "        train_dict_o2[first, second] = [third]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some utility functions\n",
    "def rand_o1():\n",
    "    '''\n",
    "    randomly picks a word from the order 1 Markov chain keys\n",
    "    '''\n",
    "    word = random.choice(list(train_dict_o1.keys())) \n",
    "    return word\n",
    "\n",
    "def rand_o2():\n",
    "    '''\n",
    "    generate a word by randomly picking a key from the order 2 Markov chain\n",
    "    '''\n",
    "    seed_word = random.choice(list(train_dict_o2.keys()))\n",
    "    mapped_word = random.choice(train_dict_o2[seed_word])\n",
    "    return mapped_word\n",
    "\n",
    "def follow_word(sentence = ['we', 'saw'], target = 5, syl = 2):\n",
    "    '''\n",
    "    generate followings words using the order 2 markov chain\n",
    "    '''\n",
    "    while syl < target:\n",
    "        seed_word = tuple(sentence)\n",
    "        \n",
    "        try:\n",
    "            mapped_word = random.choice(train_dict_o2[seed_word])\n",
    "        except KeyError: \n",
    "            mapped_word = rand_o1()\n",
    "            \n",
    "        mapped_word_syl = count_syllables(mapped_word)\n",
    "        \n",
    "        if syl + mapped_word_syl <= target:\n",
    "            sentence.append(mapped_word)\n",
    "            syl += mapped_word_syl\n",
    "        else:\n",
    "            mapped_word = rand_o2()\n",
    "            mapped_word_syl = count_syllables(mapped_word)\n",
    "            \n",
    "            if syl + mapped_word_syl <= target:\n",
    "                sentence.append(mapped_word)  \n",
    "                syl += mapped_word_syl\n",
    "                \n",
    "    print(syl) \n",
    "    sentence = \" \".join(sentence)\n",
    "    return(sentence)\n",
    "\n",
    "def new_line1():\n",
    "    '''\n",
    "    generates first line of the haiku\n",
    "    '''\n",
    "    target = 5\n",
    "    syl= target + 1\n",
    "    \n",
    "    # Pick a random first word that's fewer than 5 syllables from the order 1 markov chain\n",
    "    while syl > target:\n",
    "        first_word = rand_o1()\n",
    "        \n",
    "        # Generate the second word using the order 1 markov chain\n",
    "        try:\n",
    "            second_word = random.choice(train_dict_o1[first_word])\n",
    "        except KeyError: \n",
    "            second_word = rand_o1()\n",
    "        \n",
    "        syl = count_syllables(first_word) + count_syllables(second_word)\n",
    "        \n",
    "    sentence1 = [first_word, second_word]\n",
    "    \n",
    "    # Generate followings words using the order 2 markov chain\n",
    "    sentence1 = follow_word(sentence1)\n",
    "    return sentence1\n",
    "\n",
    "def new_line23(prev_sen = 'deep autumn water hill', target = 5):\n",
    "    '''\n",
    "    generates second or third line of the haiku\n",
    "    '''\n",
    "    syl = target + 1\n",
    "    \n",
    "    # Take the last two words from the previous sentence as the seed words for the order 2 markov chain\n",
    "    seed_word = tuple(prev_sen.split()[-2::])\n",
    "    while syl > target:\n",
    "\n",
    "        try:\n",
    "            first_word = random.choice(train_dict_o2[seed_word])\n",
    "        except KeyError: \n",
    "            first_word = rand_o1()\n",
    "            \n",
    "        seed_word = tuple([prev_sen[-1], first_word])\n",
    "        \n",
    "        try:\n",
    "            second_word = random.choice(train_dict_o2[seed_word])\n",
    "        except KeyError: \n",
    "            second_word = rand_o1()\n",
    "            \n",
    "        syl = count_syllables(first_word) + count_syllables(second_word) \n",
    "        \n",
    "    sentence = [first_word, second_word] \n",
    "    \n",
    "    # Generate followings words using the order 2 markov chain\n",
    "    sentence = follow_word(sentence, target, syl)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "7\n",
      "5\n",
      "banner across the bellies\n",
      "relief laden sails witness\n",
      "road daffodils jar\n"
     ]
    }
   ],
   "source": [
    "line = regen.value\n",
    "\n",
    "def haiku(line):\n",
    "    '''\n",
    "    generates the haiku based on user selection\n",
    "    '''\n",
    "    \n",
    "    if line == 'full haiku':\n",
    "        sentence1 = new_line1()\n",
    "        sentence2 = new_line23(sentence1, 7)\n",
    "        sentence3 = new_line23(sentence2, 5)\n",
    "        \n",
    "    if line == 'line 2 only':\n",
    "        sentence2 = new_line23(sentence1, 7)\n",
    "        \n",
    "    if line == 'line 3 only':\n",
    "        sentence3 = new_line23(sentence2, 5)\n",
    "        \n",
    "    for x in [sentence1, sentence2, sentence3]:\n",
    "        print(x)\n",
    "\n",
    "haiku(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
